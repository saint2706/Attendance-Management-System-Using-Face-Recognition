Metadata-Version: 2.4
Name: attendance-system-facial-recognition
Version: 1.0.0
Summary: Smart Attendance System using Face Recognition with DeepFace
Author: Attendance System Team
License: MIT
Requires-Python: >=3.12
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: Django==5.1.14
Requires-Dist: django-crispy-forms==2.1
Requires-Dist: dj-database-url==2.3.0
Requires-Dist: crispy-bootstrap5==2024.2
Requires-Dist: django-ratelimit==4.1.0
Requires-Dist: cryptography==43.0.3
Requires-Dist: django-silk==5.1.0
Requires-Dist: django-pandas==0.6.7
Requires-Dist: deepface==0.0.93
Requires-Dist: imutils==0.5.4
Requires-Dist: matplotlib==3.8.4
Requires-Dist: celery==5.4.0
Requires-Dist: redis==5.2.1
Requires-Dist: sentry-sdk[django]==2.43.0
Requires-Dist: seaborn==0.13.2
Requires-Dist: Pillow==10.3.0
Requires-Dist: opencv-python==4.9.0.80
Requires-Dist: scikit-learn==1.5.0
Requires-Dist: tf-keras==2.20.1
Requires-Dist: numpy==1.26.4
Requires-Dist: pandas==2.3.3
Requires-Dist: scipy==1.16.3
Requires-Dist: prometheus-client==0.20.0
Provides-Extra: dev
Requires-Dist: black==24.10.0; extra == "dev"
Requires-Dist: isort==5.13.2; extra == "dev"
Requires-Dist: flake8==7.1.1; extra == "dev"
Requires-Dist: pytest==8.3.4; extra == "dev"
Requires-Dist: pytest-django==4.9.0; extra == "dev"
Requires-Dist: pytest-cov==6.0.0; extra == "dev"
Requires-Dist: psycopg2-binary==2.9.9; extra == "dev"
Requires-Dist: pre-commit==4.0.1; extra == "dev"
Requires-Dist: pytest-playwright==0.4.4; extra == "dev"
Requires-Dist: playwright==1.49.1; extra == "dev"
Dynamic: license-file

# Attendance Management System Using Face Recognition

[![codecov](https://codecov.io/gh/saint2706/Attendance-Management-System-Using-Face-Recognition/graph/badge.svg)](https://codecov.io/gh/saint2706/Attendance-Management-System-Using-Face-Recognition)

Attendance-Management-System-Using-Face-Recognition is a fully refactored and modernized attendance solution that leverages deep learning for face recognition. It provides a seamless and automated way to track employee attendance, eliminating the need for manual record-keeping, and ships with a responsive web interface for a great user experience on any device.

![Home Page Light Theme](docs/images/home-light.png)

## Features

- **Automated Attendance:** Mark time-in and time-out effortlessly using real-time face recognition.
- **Responsive Web Interface:** A clean, modern, and intuitive UI that works beautifully on desktops, tablets, and mobile devices.
- **Admin Dashboard:** A powerful dashboard for administrators to manage employees, add user photos, and view comprehensive attendance reports.
- **Employee Dashboard:** A personalized dashboard for employees to view their own attendance records.
- **Automatic Training:** The face recognition model updates automatically when new employee photos are added.
- **Offline-ready experience:** Installable progressive web app with background sync for attendance submissions and cached UI shell.
- **Performance Optimized:** Utilizes the efficient "Facenet" model and "SSD" detector for a fast and responsive recognition experience.
- **Two-stage liveness detection:** A lightweight motion gate now complements DeepFace's anti-spoofing pass so printed photos and screen replays are rejected before attendance is marked.
- **Structured attendance sessions:** A dedicated live session view surfaces recent recognitions with timestamps, confidence, and liveness outcomes alongside start/stop controls.
- **Operational visibility:** The admin-only System Health dashboard surfaces dataset freshness, model status, recent recognition activity, and Celery worker reachability.
- **Continuous Integration:** Includes a GitHub Actions workflow to automatically run tests, ensuring code quality and stability.

## Technical Stack

- **Backend:** Django 5+ with Celery workers for async training/evaluation jobs
- **Face Recognition:** DeepFace (Facenet) + SSD detector with a motion-based liveness gate
- **Frontend:** HTML5, CSS3, Bootstrap 5, Custom CSS Design System (installable PWA)
- **JavaScript:** Vanilla JS (no framework dependencies)
- **Database & cache:** Configurable via `DATABASE_URL` (PostgreSQL recommended; SQLite for local development) and Redis for Celery/async queues
- **Observability:** Sentry integration plus Silk for request profiling
- **Testing & CI:** Pytest with coverage + Playwright UI checks, executed in GitHub Actions

## Getting Started

### Prerequisites

- Python 3.12 or higher
- A webcam for face recognition

### Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/saint2706/Attendance-Management-System-Using-Face-Recognition.git
    cd Attendance-Management-System-Using-Face-Recognition
    ```

2.  **Create and activate a virtual environment:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```

3.  **Install the dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Configure environment variables:**
    - Copy `.env.example` to `.env`.
    - Generate secrets if you don't already have them:
      ```bash
      python - <<'PY'
      from cryptography.fernet import Fernet
      import secrets

      print('DJANGO_SECRET_KEY=', secrets.token_urlsafe(50))
      print('DATA_ENCRYPTION_KEY=', Fernet.generate_key().decode())
      print('FACE_DATA_ENCRYPTION_KEY=', Fernet.generate_key().decode())
      PY
      ```
    - Paste the values into `.env` and keep the same keys across runs so encrypted face data remains readable locally.
    - (Optional) Start the bundled Postgres service if you want to run against PostgreSQL instead of SQLite:
      ```bash
      docker compose up -d postgres
      ```

5.  **Run database migrations:**
    ```bash
    python manage.py migrate
    ```

6.  **Create a superuser (admin account):**
    ```bash
    python manage.py createsuperuser
    ```
    Follow the prompts to create your admin username, email, and password.

7.  **Run the development server:**
    ```bash
    python manage.py runserver
    ```
    The application will be available at `http://127.0.0.1:8000/`.

8.  **Collect static assets (including the PWA shell) before packaging builds:**
    ```bash
    python manage.py collectstatic
    ```
    This ensures the generated icons, `manifest.json`, and `sw.js` are published alongside the rest of the static files when you deploy with WhiteNoise or another static file server.

## Quick demo (synthetic data)

Use the bundled helper to generate an **encrypted synthetic** dataset and matching demo accounts:

```bash
make demo
```

This will:

- Apply migrations.
- Generate synthetic avatars into `sample_data/face_recognition_data/training_dataset/` and copy them to `face_recognition_data/training_dataset/` so the runtime pipeline can load them immediately.
- Create a demo superuser (`demo_admin` / `demo_admin_pass`).
- Create three matching demo users (`user_001`, `user_002`, `user_003`), all with password `demo_user_pass`.

Start the server with `python manage.py runserver` and sign in with the demo credentials above. The synthetic dataset is fully encrypted with the configured `DATA_ENCRYPTION_KEY`, so embeddings and caching behave the same as production assets.

Prefer to inspect or regenerate the dataset manually? Run `python scripts/bootstrap_demo.py --help` for options, or consult [sample_data/README.md](sample_data/README.md) for a deeper walkthrough of how the encrypted JPEGs are produced and reused across demo/test runs.

### Run a live attendance session

- Visit **Dashboard → Attendance Session** to view a structured, auto-refreshing log of recent recognition attempts with liveness outcomes and match confidence.
- The first-run checklist on the dashboard will prompt you to register an employee, add photos, and train the model if any prerequisites are missing.
- Use the check-in/check-out controls on the session page to start the same webcam-based flow used elsewhere in the app while keeping an eye on the live feed.

## Performance Monitoring

Silk is bundled to profile database queries, view timings, and cache usage without leaving the Django admin. The dependency is already pinned in `requirements.txt`/`pyproject.toml`, so installing the project requirements pulls it in automatically.

1. **Apply Silk migrations** after installing dependencies any time new environments are set up:
   ```bash
   python manage.py migrate
   ```
   This creates the `silk_*` tables used to persist profiling results.
2. **Accessing the dashboard:**
   - In development (`DJANGO_DEBUG=1`) visit `http://127.0.0.1:8000/silk/` to inspect live profiles.
   - In non-debug deployments Silk requires authentication and staff status. Log in with a staff or superuser account before visiting `/silk/`; non-staff users receive a permission error and unauthenticated visitors are redirected to the login page.
3. **Production guardrails:** keep the middleware enabled only when you actively need profiling, and clear the Silk tables regularly in long-running environments to manage database size.

## Documentation

For more detailed information, please refer to the full documentation:

- **[User Guide](USER_GUIDE.md)**: A comprehensive guide for non-programmers on using and understanding the system.
- **[Developer Guide](DEVELOPER_GUIDE.md)**: Information for developers on the system's architecture, evaluation pipeline, management commands, and environment configuration (including encryption keys).
- **[Contributing Guide](CONTRIBUTING.md)**: Instructions for setting up the development environment and contributing to the project.
- **[API Reference](API_REFERENCE.md)**: Details on URL patterns, API endpoints, and command-line tools.
- **[Architecture Overview](ARCHITECTURE.md)**: A high-level overview of the system architecture and data flows.
- **[Data Card](DATA_CARD.md)**: Comprehensive documentation on the dataset, including privacy policies and data splits.
- **[Liveness Evaluation](docs/liveness_evaluation.md)**: Methodology and results for the new motion-based anti-spoofing stage plus guidance for running `manage.py evaluate_liveness` locally.
- **[Deployment Guide](DEPLOYMENT.md)**: Step-by-step instructions for building the Docker image, configuring Compose services, managing environment variables, and hardening production deployments.
- **[Fairness & Limitations](docs/FAIRNESS_AND_LIMITATIONS.md)**: Methodology, findings, and follow-up actions for the fairness and robustness audit plus guidance on how to rerun it locally.

## Reproducibility

The repository can generate a tiny, synthetic dataset under
`sample_data/face_recognition_data/training_dataset/` so reviewers can exercise
the full recognition pipeline without requesting encrypted production assets.
Run the following command after installing dependencies to regenerate the
metrics referenced in the documentation (the dataset will be created on the fly if missing):

```bash
make reproduce
```

The target launches `scripts/reproduce_sample_results.py`, which points the
evaluation harness at the bundled dataset, seeds the random number generators,
and saves artifacts (metrics JSON, confusion matrix, per-sample CSV) to
`reports/sample_repro/`. You can supply your own dataset or split CSV by
invoking the script directly:

```bash
python scripts/reproduce_sample_results.py --dataset-root /path/to/your/data --split-csv custom.csv
```

The script overwrites neither `face_recognition_data/` nor production caches; it
patches the dataset root in-memory so regular deployments remain unchanged.

## Limitations & Responsible Use

Face biometrics introduce safety and ethical constraints that require explicit monitoring. Run `python manage.py fairness_audit --split-csv reports/splits.csv --reports-dir reports/fairness` whenever the dataset changes to capture per-role, per-site, per-source, and per-lighting metrics. The resulting tables in `reports/fairness/summary.md` highlight buckets where the False Acceptance Rate (FAR) or False Rejection Rate (FRR) deviates from the global average. Review the [Fairness & Limitations](docs/FAIRNESS_AND_LIMITATIONS.md) report alongside the [DATA_CARD.md](DATA_CARD.md) before rolling out models to new locations or populations.

## Deployment Configuration

When deploying to staging or production, configure the following environment variables so that session cookies remain secure and expire after periods of inactivity. Boolean values accept `1`, `true`, `yes`, or `on` (case-insensitive). Use the development settings module (`attendance_system_facial_recognition.settings`) locally and for automated tests. Production deployments should set `DJANGO_SETTINGS_MODULE=attendance_system_facial_recognition.settings.production` so the hardened database configuration is loaded.

Review the [Security & Compliance Guide](docs/security.md) for secret management, HTTPS/SSL hardening, and operational checklists that build on these deployment notes.

The Progressive Web App resources are exposed at `/manifest.json` and `/sw.js`. Ensure these paths are routed to Django so the manifest and service worker can be cached by browsers during install.

| Environment variable | Purpose | Recommended staging value | Recommended production value |
| --- | --- | --- | --- |
| `DATABASE_URL` | Connection string parsed with [`dj-database-url`](https://github.com/jazzband/dj-database-url). | `postgres://user:pass@db:5432/attendance` | `postgres://user:pass@db:5432/attendance` |
| `DATABASE_CONN_MAX_AGE` | Persistent connection lifetime in seconds (`0` disables pooling). | `60` | `600` |
| `DATABASE_SSL_REQUIRE` | Force `sslmode=require` for managed Postgres providers. | `false` | `true` |
| `DJANGO_SESSION_COOKIE_SECURE` | Send the session cookie only over HTTPS. | `true` | `true` |
| `DJANGO_SESSION_COOKIE_HTTPONLY` | Prevent client-side scripts from reading the session cookie. | `true` | `true` |
| `DJANGO_CSRF_COOKIE_SECURE` | Send the CSRF cookie only over HTTPS. | `true` | `true` |
| `DJANGO_SESSION_COOKIE_SAMESITE` | Restrict cross-site cookie usage. | `Lax` | `Lax` |
| `DJANGO_SESSION_COOKIE_AGE` | Maximum session age (seconds) before inactivity timeout. | `1800` (30 minutes) | `1800` (30 minutes) |
| `DJANGO_SESSION_EXPIRE_AT_BROWSER_CLOSE` | Drop the session when the browser closes. | `true` | `true` |

Ensure these variables are present in the staging and production deployment manifests (e.g., `.env` files, container secrets, or platform configuration) before rolling out new builds.

### Observability and error tracking

The production settings initialise [Sentry](https://sentry.io/) automatically when the DSN is supplied. Configure the following environment variables to tailor telemetry to each deployment target:

| Environment variable | Purpose | Recommended staging value | Recommended production value |
| --- | --- | --- | --- |
| `SENTRY_DSN` | Enables Sentry ingestion for the project. | `https://<public>@sentry.io/<project>` | `https://<public>@sentry.io/<project>` |
| `SENTRY_ENVIRONMENT` | Distinguishes environments inside the Sentry dashboards. | `staging` | `production` |
| `SENTRY_RELEASE` | Associates events with build artefacts for source maps and regression tracking. | Git commit SHA | Git tag or release identifier |
| `SENTRY_TRACES_SAMPLE_RATE` | Fraction (0.0–1.0) of requests captured for APM tracing. | `0.1` | `0.2` |
| `SENTRY_PROFILES_SAMPLE_RATE` | Fraction (0.0–1.0) of traces that include profiling data. | `0.0` | `0.05` |
| `SENTRY_SEND_DEFAULT_PII` | Toggle for sending user-identifiable attributes; defaults to scrubbing PII. | `false` | `false` |

With `SENTRY_SEND_DEFAULT_PII` disabled, the integration strips cookies, authorisation headers, and user attributes before dispatching events so that production telemetry complies with internal privacy requirements. Operators that need richer context can opt in by setting `SENTRY_SEND_DEFAULT_PII=true` after completing a privacy impact assessment.

#### Operational dashboards

- **Issues**: Monitor unhandled exceptions and message breadcrumbs from the Sentry *Issues* dashboard. Pin the view filtered by `environment:production` to quickly detect regressions after each deployment.
- **Performance**: Track request latency, throughput, and slow transactions with the *Performance* dashboard. Enable sampling via `SENTRY_TRACES_SAMPLE_RATE` to populate the charts and configure alerts for p95 latency regressions.
- **Real-time**: For incident response, use Sentry's *Releases* view to correlate deploys with spikes in error volume, and subscribe the operations channel to release health alerts.
- **In-app health**: Use the Django admin System Health page to confirm camera connectivity, dataset freshness, model recency, recent recognition outcomes, and Celery worker reachability without leaving the UI.

### Containerized deployment workflow

The repository ships with a production-ready `Dockerfile` and Compose definition so you can build and run the stack with minimal host dependencies. The commands below assume Docker Engine 24+ and Docker Compose v2 are installed locally.

1. **Prepare environment variables**
   - Create a secrets file (for example, `.env.production`) that exports:
     - `DJANGO_SECRET_KEY` — a strong, unique secret key.
     - `DATA_ENCRYPTION_KEY` and `FACE_DATA_ENCRYPTION_KEY` — Fernet keys. Generate each with `python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"`.
     - `DJANGO_ALLOWED_HOSTS` — comma-separated hostnames served by the deployment.
     - Database credentials (`POSTGRES_DB`, `POSTGRES_USER`, `POSTGRES_PASSWORD`) if you override the defaults.
   - Load the file automatically by placing it next to `docker-compose.yml` and referencing it with `docker compose --env-file .env.production ...`.

2. **Build the application image**
   ```bash
   docker compose --env-file .env.production build web
   ```

3. **Apply database migrations inside the container image**
   ```bash
   docker compose --env-file .env.production run --rm web python manage.py migrate
   ```

4. **Start the web and worker services**
   ```bash
   docker compose --env-file .env.production up -d web celery
   ```

5. **Tail logs for troubleshooting**
   ```bash
   docker compose logs -f web celery
   ```

The `web` service serves the Django application through Gunicorn on port `8000`, while the `celery` service reuses the same image to execute asynchronous jobs. Static assets are collected during the image build, so no additional setup is required before exposing the container behind a reverse proxy.

### Database migration & testing workflow

1.  **Local development:**
    - Copy `.env.example` to `.env` and adjust credentials.
    - Start the Postgres service from the provided Docker Compose profile:
      ```bash
      docker compose up -d postgres
      ```
    - Apply schema migrations against Postgres and run the Django test suite:
      ```bash
      python manage.py migrate
      pytest
      ```

2.  **Continuous Integration:** Configure the CI job to export `DATABASE_URL` (for example, `postgres://postgres:postgres@localhost:5432/postgres`) before invoking `pytest` so the same migrations and tests execute against Postgres automatically.
    - Coverage is enforced in CI; the suite fails if overall coverage drops below 60%, and the Codecov badge at the top of this README reflects the latest run.

## Evaluation & Benchmarking

The repository ships with an evaluation harness that reuses the exact face-recognition pipeline deployed in production. It loads the encrypted dataset, computes embeddings through DeepFace, and aggregates the metrics required for referee-quality reports (accuracy, precision, recall, macro F1, FAR, FRR, confusion matrix, and a threshold sweep).

1. **Prepare dataset splits (optional but recommended):**
   ```bash
   python manage.py prepare_splits --seed 42
   ```
   This command writes `reports/splits.csv`, which identifies the test split consumed during evaluation. If the file is missing the evaluator falls back to scanning the entire `face_recognition_data/training_dataset/` tree.
2. **Run the evaluation:**
   ```bash
   python manage.py eval --split-csv reports/splits.csv
   ```
   The command accepts additional knobs such as `--threshold`, `--threshold-start/stop/step`, `--max-samples`, and `--reports-dir` for ad-hoc experiments. A convenience shortcut is also available via `make evaluate`.
3. **Inspect the reports:** artifacts are written to `reports/evaluation/`:
   - `metrics_summary.json` – accuracy/precision/recall/F1/FAR/FRR plus bookkeeping stats.
   - `sample_predictions.csv` – per-image ground truth, candidate match, distance, and predicted label.
   - `confusion_matrix.csv` and `confusion_matrix.png` – tabular and visual confusion matrices.
   - `threshold_sweep.csv` and `threshold_sweep.png` – FAR/FRR/accuracy/F1 for each distance threshold in the sweep.

Because the evaluator defers to the same dataset cache used during attendance marking, results remain reproducible and consistent with the live service.

## Face-Matching Metric

The recognition pipeline compares embeddings with cosine similarity:

- **Similarity:** `sim(A, B) = (A · B) / (||A|| ||B||)`
- **Cosine distance:** `d(A, B) = 1 − sim(A, B)`

Attendance is accepted when the cosine distance is less than or equal to `RECOGNITION_DISTANCE_THRESHOLD`, which defaults to **0.4** in this repository. Tightening the threshold reduces false accepts while loosening it mitigates false rejects. The evaluation harness (`python manage.py eval` or `make evaluate`) sweeps a configurable range via `--threshold-start/stop/step` and records FAR/FRR trade-offs in `reports/evaluation/threshold_sweep.csv`, making it easy to justify any threshold adjustment before shipping.

3.  **Production deployments:** Run `python manage.py migrate` as part of the release pipeline after setting the new database variables. Review logs for schema drift and keep a recent backup of the managed Postgres instance before upgrading.

## License

This project is licensed under the terms of the [LICENSE](LICENSE) file.
